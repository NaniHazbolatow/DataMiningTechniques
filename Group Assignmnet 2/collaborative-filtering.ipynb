{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:12:02.086945Z",
     "start_time": "2025-05-15T19:11:44.224959Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, expr\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HotelRecommendationALS\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# loading in the cleaned training data\n",
    "train_data = pl.read_csv('data/cleaned_training_data.csv')\n",
    "test_data = pl.read_csv('data/cleaned_test_data.csv')\n",
    "\n",
    "# I will drop unnecessary columns\n",
    "train_data = train_data.drop(['prop_log_historical_price', 'price_usd', 'parsed_date', 'year', 'month', 'day', 'search_hour', 'day_of_week', 'year_month', 'date_time', 'prop_historical_price', 'price_usd_per_night_test', 'price_ratio', 'position', 'gross_bookings_usd', 'click_bool']). \\\n",
    "    rename({'price_usd_without_promo': 'price_usd'})\n",
    "\n",
    "test_data = test_data.drop(['prop_log_historical_price', 'price_usd', 'parsed_date', 'year', 'month', 'day', 'search_hour', 'day_of_week', 'year_month', 'date_time', 'prop_historical_price', 'price_usd_per_night_test', 'price_ratio']). \\\n",
    "    rename({'price_usd_without_promo': 'price_usd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7674f2f49a4a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T19:15:03.926879Z",
     "start_time": "2025-05-15T19:14:57.827589Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating the dataframe for the CatBoostRanker\n",
    "train_df = train_data.to_pandas()\n",
    "test_df = test_data.to_pandas()\n",
    "\n",
    "# # I will train the model on a subset\n",
    "# train_df = train_df[train_df['srch_id'].isin(train_df['srch_id'].unique()[:4000])]\n",
    "# print(train_df.shape) # 2492 observations\n",
    "\n",
    "# # test model subset\n",
    "# test_subset = test_data.to_pandas().copy()\n",
    "# test_subset = test_subset[test_subset['srch_id'].isin(train_df['srch_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create an implicit feedback dataset\n",
    "# For collaborative filtering, we need (user, item, rating) format\n",
    "# Here, srch_id = user, prop_id = item, and we'll create a rating based on booking_bool\n",
    "# If booking_bool=1, we'll give it a higher weight\n",
    "\n",
    "# Create rating values based on booking behavior\n",
    "# Rating scale: booking=5, click only=1, impression only=0.5\n",
    "#train_df['rating'] = train_df['booking_bool'] * 4 + 1.0\n",
    "\n",
    "# Keep only the columns needed for ALS\n",
    "als_data = train_df[['srch_id', 'prop_id', 'booking_bool']].copy()\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(als_data)\n",
    "\n",
    "# Ensure correct types and no nulls for ALS\n",
    "from pyspark.sql.functions import col\n",
    "spark_df = spark_df.dropna(subset=[\"srch_id\", \"prop_id\", \"booking_bool\"])\n",
    "spark_df = spark_df.withColumn(\"srch_id\", col(\"srch_id\").cast(\"integer\"))\n",
    "spark_df = spark_df.withColumn(\"prop_id\", col(\"prop_id\").cast(\"integer\"))\n",
    "spark_df = spark_df.withColumn(\"booking_bool\", col(\"booking_bool\").cast(\"float\"))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "(training_data, validation_data) = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create an ALS model\n",
    "als = ALS(\n",
    "    maxIter=15,\n",
    "    regParam=0.01,\n",
    "    userCol=\"srch_id\",\n",
    "    itemCol=\"prop_id\",\n",
    "    ratingCol=\"booking_bool\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    implicitPrefs=True,  # Use implicit feedback\n",
    "    alpha=10.0,  # Confidence parameter for implicit feedback\n",
    "    nonnegative=True,  # Use non-negative factorization for better interpretability\n",
    "    rank=80  # Number of latent factors\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Make predictions on validation data\n",
    "predictions = model.transform(validation_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "# First convert test data to Spark DataFrame with the needed columns\n",
    "test_df = test_data.to_pandas()\n",
    "test_spark_df = spark.createDataFrame(test_df[['srch_id', 'prop_id']])\n",
    "\n",
    "# Generate predictions for all search-property pairs in test data\n",
    "test_predictions = model.transform(test_spark_df)\n",
    "\n",
    "# Generate top N recommendations for each search\n",
    "N = 5  # Number of recommendations per search\n",
    "search_recs = model.recommendForAllUsers(N)\n",
    "\n",
    "# Explode the recommendations column to get a flat table\n",
    "search_recs = search_recs.select(\n",
    "    col(\"srch_id\"),\n",
    "    expr(\"explode(recommendations)\").alias(\"recommendation\")\n",
    ").select(\n",
    "    col(\"srch_id\"),\n",
    "    col(\"recommendation.prop_id\").alias(\"prop_id\"),\n",
    "    col(\"recommendation.rating\").alias(\"pred_score\")\n",
    ")\n",
    "\n",
    "# Calculate softmax scores for ranking\n",
    "# First, collect the data back to pandas\n",
    "search_recs_pd = search_recs.toPandas()\n",
    "\n",
    "# Apply softmax function to prediction scores\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# Group by search_id and apply softmax within each group\n",
    "search_recs_pd['softmax_score'] = search_recs_pd.groupby('srch_id')['pred_score'].transform(\n",
    "    lambda x: softmax(x.values)\n",
    ")\n",
    "\n",
    "# Sort by search_id and prediction score (descending)\n",
    "ranked_recs = search_recs_pd.sort_values(by=['srch_id', 'pred_score'], ascending=[True, False])\n",
    "print(ranked_recs.head(10))\n",
    "\n",
    "# Save the results\n",
    "ranked_recs[['srch_id', 'pred_score', 'softmax_score', 'prop_id']].to_csv('als_recommendations.csv', index=False)\n",
    "\n",
    "# For full test dataset predictions (not just top N)\n",
    "# This will generate a score for every search-property pair\n",
    "full_test_predictions = test_predictions.select(\n",
    "    col(\"srch_id\"),\n",
    "    col(\"prop_id\"),\n",
    "    col(\"prediction\").alias(\"pred_score\")\n",
    ").toPandas()\n",
    "\n",
    "# Apply softmax for full predictions\n",
    "full_test_predictions['softmax_score'] = full_test_predictions.groupby('srch_id')['pred_score'].transform(\n",
    "    lambda x: softmax(x.values)\n",
    ")\n",
    "\n",
    "# Sort by search_id and prediction score (descending)\n",
    "full_ranked = full_test_predictions.sort_values(by=['srch_id', 'pred_score'], ascending=[True, False])\n",
    "\n",
    "# Save full predictions\n",
    "full_ranked[['srch_id', 'pred_score', 'softmax_score', 'prop_id']].to_csv('als_full_predictions.csv', index=False)\n",
    "\n",
    "# Stop Spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bc045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "als_full_predictions = pd.read_csv('als_full_predictions.csv')\n",
    "als_full_predictions[['srch_id', 'prop_id']].to_csv('als_full_predictions_ids.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f7beb",
   "metadata": {},
   "source": [
    "Root-mean-square error = 1.2053121495196557\n",
    "        srch_id  prop_id  pred_score  softmax_score\n",
    "189095        1    53341    0.760762       0.204566\n",
    "189096        1    95307    0.753495       0.203085\n",
    "189097        1    88218    0.729622       0.198294\n",
    "189098        1    65606    0.725878       0.197553\n",
    "189099        1    41488    0.720551       0.196503\n",
    "472925        4    48512    0.510664       0.204785\n",
    "472926        4    51555    0.493643       0.201329\n",
    "472927        4   114177    0.484217       0.199440\n",
    "472928        4    45412    0.475473       0.197704\n",
    "472929        4   140304    0.470590       0.196741\n",
    "Best Rank: 80\n",
    "Best RegParam: 0.01\n",
    "Best MaxIter: 15\n",
    "Best Alpha: 10.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
